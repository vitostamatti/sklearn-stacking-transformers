{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_boston\n",
    "# X, y = make_regression(n_samples=1000)\n",
    "\n",
    "data = load_boston()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1123)\n",
    "\n",
    "class ClassificationWeightsOptimizer(object):\n",
    "\n",
    "    def __init__(self, score_func=None):\n",
    "        self.score_func = score_func\n",
    "\n",
    "    @staticmethod\n",
    "    def objective(weights, y_true, y_pred):\n",
    "        y_ens = np.round(np.average(y_pred, axis=1, weights=weights),0).astype(int)\n",
    "        return (1-accuracy_score(y_true, y_ens))\n",
    "\n",
    "    def _run_opt(self, y_true, y_pred):\n",
    "        w0 = np.random.uniform(size=y_pred.shape[1])\n",
    "        bounds = [(0.,1.)] * y_pred.shape[1]\n",
    "        cons = [{'type': 'eq','fun': lambda w: w.sum() - 1}]\n",
    "        res = minimize(self.objective,w0,\n",
    "            args=(y_true,y_pred),method='SLSQP',bounds=bounds,\n",
    "            options={'disp':False, 'maxiter':1000},constraints=cons)\n",
    "\n",
    "        return (res.fun, res.x)\n",
    "\n",
    "    def run_parallel(self, iters, y_true, y_pred):\n",
    "        results = Parallel(n_jobs=-1)(delayed(self._run_opt)(y_true, y_pred) for i in range(iters))\n",
    "        r, w = [re[0] for re in results], [re[1] for re in results]\n",
    "        best_score = np.min(r)    \n",
    "        best_weights = w[r.index(best_score)]\n",
    "        print('\\nOptimized weights:')\n",
    "        print(f\"Best Score: {best_score}\")\n",
    "        for i,w in enumerate(best_weights):\n",
    "            print(f'Weight {i}: {w:.4f}')\n",
    "        return {\"best_score\":best_score,\"best_weights\":best_weights}\n",
    "\n",
    "\n",
    "    def run(self, iters, y_true, y_pred):\n",
    "        results_list = [] \n",
    "        weights_list = []  \n",
    "        for k in range(iters):\n",
    "            r,w = self._run_opt(y_true, y_pred)\n",
    "            results_list.append(r)\n",
    "            weights_list.append(w)\n",
    "\n",
    "        best_score = np.min(results_list)    \n",
    "        best_weights = weights_list[results_list.index(best_score)]\n",
    "        \n",
    "        print('\\nOptimized weights:')\n",
    "        print(f\"Best Score: {best_score}\")\n",
    "        for i,w in enumerate(best_weights):\n",
    "            print(f'Weight {i}: {w:.4f}')\n",
    "\n",
    "        return {\"best_score\":best_score,\"best_weights\":best_weights}\n",
    "\n",
    "\n",
    "class RegressionWeightsOptimizer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective(weights, y_true, y_pred):\n",
    "        y_ens = np.average(y_pred, axis=1, weights=weights)\n",
    "        return mean_squared_error(y_true, y_ens)\n",
    "\n",
    "    def _run_opt(self, y_true, y_pred):\n",
    "        # w0 = np.random.uniform(size=y_pred.shape[1])\n",
    "        w0 = [1/y_pred.shape[1] for i in range(y_pred.shape[1])]\n",
    "        bounds = [(0.,1.)] * y_pred.shape[1]\n",
    "        cons = [{'type': 'eq','fun': lambda w: w.sum() - 1}]\n",
    "        res = minimize(self.objective,w0,args=(y_true,y_pred),\n",
    "            method='SLSQP',bounds=bounds,options={'disp':False, 'maxiter':1000},\n",
    "            constraints=cons)\n",
    "            \n",
    "        return (res.fun, res.x)\n",
    "\n",
    "    def run_parallel(self, iters, y_true, y_pred):\n",
    "        results = Parallel(n_jobs=-1)(delayed(self._run_opt)(y_true, y_pred) for i in range(iters))\n",
    "        r, w = [re[0] for re in results], [re[1] for re in results]\n",
    "        best_score = np.min(r)    \n",
    "        best_weights = w[r.index(best_score)]\n",
    "        print('\\nOptimized weights:')\n",
    "        print(f\"Best Score: {best_score}\")\n",
    "        for i,w in enumerate(best_weights):\n",
    "            print(f'Weight {i}: {w:.4f}')\n",
    "        return {\"best_score\":best_score,\"best_weights\":best_weights}\n",
    "\n",
    "\n",
    "    def run(self, iters, y_true, y_pred):\n",
    "        results_list = [] \n",
    "        weights_list = []  \n",
    "        for k in range(iters):\n",
    "            r,w = self._run_opt(y_true, y_pred)\n",
    "            results_list.append(r)\n",
    "            weights_list.append(w)\n",
    "\n",
    "        best_score = np.min(results_list)    \n",
    "        best_weights = weights_list[results_list.index(best_score)]\n",
    "        \n",
    "        print('\\nOptimized weights:')\n",
    "        print(f\"Best Score: {best_score}\")\n",
    "        for i,w in enumerate(best_weights):\n",
    "            print(f'Weight {i}: {w:.4f}')\n",
    "\n",
    "        return {\"best_score\":best_score,\"best_weights\":best_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "estimators = [\n",
    "    ('m1', LinearRegression()),\n",
    "    ('m2', ExtraTreesRegressor()),\n",
    "    ('m3', RandomForestRegressor()),\n",
    "    ('m4', GradientBoostingRegressor()),\n",
    "    ('m5', KNeighborsRegressor()),\n",
    "]\n",
    "\n",
    "# voting = VotingRegressor(estimators, weights=None, n_jobs=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def _fit_single_estimator(model, X, y):\n",
    "    return model.fit(X,y)\n",
    "\n",
    "\n",
    "class AutoVotingRegressor():\n",
    "    def __init__(self, estimators, weights=None, n_jobs=-1, verbose=False):\n",
    "        \n",
    "        self.estimators_ = estimators\n",
    "        self.weights_ = weights\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose=verbose\n",
    "        self.n_estimators = len(self.estimators_)\n",
    "\n",
    "        self.w_opt = RegressionWeightsOptimizer()\n",
    "\n",
    "\n",
    "        self.estimators__ = estimators\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls.\"\"\"\n",
    "        return np.asarray([est[1].predict(X) for est in self.estimators_]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.average(self._predict(X), axis=1, weights=self.weights_)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        names, models = [e[0] for e in self.estimators__],[e[1] for e in self.estimators__]\n",
    "        fitted_models = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_single_estimator)(\n",
    "                clone(m),\n",
    "                X,\n",
    "                y\n",
    "            )\n",
    "            for m in models\n",
    "        )\n",
    "        self.estimators_ = [(names[i],fitted_models[i]) for i in range(self.n_estimators)]\n",
    "        return self\n",
    "\n",
    "    def compute_weights(self, X, y, eval_size=0.1, iters=1000):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=eval_size)\n",
    "\n",
    "        self.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = self._predict(X_test)\n",
    "\n",
    "        r = self.w_opt.run_parallel(iters, y_test, y_pred)\n",
    "\n",
    "        self.weights_ = r['best_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized weights:\n",
      "Best Score: 8.25379237381497\n",
      "Weight 0: 0.0000\n",
      "Weight 1: 0.0000\n",
      "Weight 2: 0.0000\n",
      "Weight 3: 1.0000\n",
      "Weight 4: 0.0000\n"
     ]
    }
   ],
   "source": [
    "voting = AutoVotingRegressor(estimators=estimators)\n",
    "\n",
    "voting.compute_weights(X_train, y_train)\n",
    "\n",
    "\n",
    "# Optimized weights:\n",
    "# Best Score: 5.186880268514192\n",
    "# Weight 0: 0.1047\n",
    "# Weight 1: 0.4823\n",
    "# Weight 2: 0.0000\n",
    "# Weight 3: 0.3239\n",
    "# Weight 4: 0.0891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;m1&#x27;, LinearRegression()),\n",
       "                            (&#x27;m2&#x27;, ExtraTreesRegressor()),\n",
       "                            (&#x27;m3&#x27;, RandomForestRegressor()),\n",
       "                            (&#x27;m4&#x27;, GradientBoostingRegressor()),\n",
       "                            (&#x27;m5&#x27;, KNeighborsRegressor()), (&#x27;m6&#x27;, Lasso()),\n",
       "                            (&#x27;m7&#x27;, Ridge())],\n",
       "                n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;m1&#x27;, LinearRegression()),\n",
       "                            (&#x27;m2&#x27;, ExtraTreesRegressor()),\n",
       "                            (&#x27;m3&#x27;, RandomForestRegressor()),\n",
       "                            (&#x27;m4&#x27;, GradientBoostingRegressor()),\n",
       "                            (&#x27;m5&#x27;, KNeighborsRegressor()), (&#x27;m6&#x27;, Lasso()),\n",
       "                            (&#x27;m7&#x27;, Ridge())],\n",
       "                n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m5</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m6</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>m7</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('m1', LinearRegression()),\n",
       "                            ('m2', ExtraTreesRegressor()),\n",
       "                            ('m3', RandomForestRegressor()),\n",
       "                            ('m4', GradientBoostingRegressor()),\n",
       "                            ('m5', KNeighborsRegressor()), ('m6', Lasso()),\n",
       "                            ('m7', Ridge())],\n",
       "                n_jobs=-1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9202159372071448"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.score(X_test, y_test)\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized weights:\n",
      "Best Score: 0.0888888888888889\n",
      "Weight 0: 0.0443\n",
      "Weight 1: 0.3285\n",
      "Weight 2: 0.0000\n",
      "Weight 3: 0.0000\n",
      "Weight 4: 0.3337\n",
      "Weight 5: 0.2934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.0888888888888889,\n",
       " 'best_weights': array([0.04430314, 0.32853739, 0.        , 0.        , 0.33374427,\n",
       "        0.2934152 ])}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.run(iters=1, y_true=y, y_pred=val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized weights:\n",
      "Best Score: 0.0888888888888889\n",
      "Weight 0: 0.0000\n",
      "Weight 1: 0.1794\n",
      "Weight 2: 0.2146\n",
      "Weight 3: 0.0000\n",
      "Weight 4: 0.3485\n",
      "Weight 5: 0.2575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_score': 0.0888888888888889,\n",
       " 'best_weights': array([1.11022302e-16, 1.79394462e-01, 2.14585699e-01, 0.00000000e+00,\n",
       "        3.48503571e-01, 2.57516268e-01])}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.run_parallel(iters=100, y_true=y_val, y_pred=val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, Lasso\n",
    "from math import sqrt\n",
    "\n",
    "NFOLDS = 6\n",
    "SEED = 123\n",
    "\n",
    "\n",
    "\n",
    "def get_oof(m, X_train, y_train, X_test, kf):\n",
    "    ntrain = X_train.shape[0]\n",
    "    ntest = X_test.shape[0]\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        x_tr = X_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = X_train[test_index]\n",
    "\n",
    "        m.fit(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = m.predict(x_te)\n",
    "        oof_test_skf[i, :] = m.predict(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "model_1 = LinearRegression()\n",
    "model_2 = RandomForestRegressor()\n",
    "model_3 = ExtraTreesRegressor()\n",
    "model_4 = Ridge()\n",
    "all_models = [model_1, model_2, model_3, model_4]\n",
    "\n",
    "oof = [get_oof(m, X_train, y_train, X_test, kf) for m in all_models]\n",
    "oof_trains, oof_tests = [p[0] for p in oof],[p[1] for p in oof]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.10217436, 29.22766667, 28.55516667, 30.73796599],\n",
       "       [16.13644488, 16.78016667, 16.69216667, 15.54842484],\n",
       "       [24.50123952, 21.73333333, 22.3765    , 24.0333555 ],\n",
       "       [ 8.65779712, 12.595     , 13.03416667, 10.50764633],\n",
       "       [16.64650655, 19.3745    , 20.28      , 17.3942869 ],\n",
       "       [20.35858567, 15.5235    , 16.01883333, 20.55919493],\n",
       "       [17.14314833, 16.06566667, 17.25516667, 17.66305658],\n",
       "       [29.1170889 , 25.35883333, 25.24283333, 28.64992499],\n",
       "       [22.30472703, 24.498     , 24.79233333, 22.84451068],\n",
       "       [19.61202601, 19.63383333, 19.80983333, 20.15094986],\n",
       "       [ 6.95782485,  7.96583333,  8.5115    ,  6.89361638],\n",
       "       [36.49925801, 44.66016667, 44.39416667, 36.13784665],\n",
       "       [15.34226987, 14.093     , 16.733     , 17.25835355],\n",
       "       [22.93937797, 18.14133333, 20.50833333, 24.97382215],\n",
       "       [25.31982075, 26.10433333, 25.84966667, 25.33839425],\n",
       "       [ 6.02647584,  8.6235    ,  8.88416667,  6.24192213],\n",
       "       [21.76602153, 21.51433333, 20.659     , 21.55098766],\n",
       "       [22.5129532 , 20.03183333, 20.19816667, 22.20047205],\n",
       "       [21.61377205, 20.45283333, 20.70233333, 21.73173521],\n",
       "       [35.27722794, 31.59466667, 31.48083333, 34.9515256 ],\n",
       "       [19.59220702, 20.88916667, 21.2375    , 19.44079199],\n",
       "       [15.96376797, 19.8595    , 19.55466667, 16.32082705],\n",
       "       [14.07591276, 15.40933333, 14.04583333, 13.87581124],\n",
       "       [20.38466577, 19.48516667, 19.63883333, 20.4380016 ],\n",
       "       [20.28532855, 17.2795    , 17.57516667, 22.32548688],\n",
       "       [38.66146647, 46.79466667, 46.885     , 38.12058345],\n",
       "       [ 9.732914  , 12.7695    , 13.79516667, 11.6009786 ],\n",
       "       [ 9.08765396,  9.36933333,  8.84583333,  9.40863934],\n",
       "       [18.21429579, 16.26416667, 15.85516667, 18.57730684],\n",
       "       [25.11942724, 23.51783333, 23.665     , 25.40450489],\n",
       "       [20.25909915, 18.94633333, 18.76883333, 20.03926695],\n",
       "       [17.12397909, 18.00183333, 17.84983333, 16.78604689],\n",
       "       [18.86650868, 15.61416667, 14.971     , 19.44400066],\n",
       "       [31.28766952, 29.47433333, 29.995     , 30.89119844],\n",
       "       [12.63731402, 13.135     , 13.576     , 11.9120873 ],\n",
       "       [11.94001054, 13.42833333, 14.181     , 11.32346103],\n",
       "       [27.23773434, 28.63933333, 26.31766667, 26.31738609],\n",
       "       [11.56903615, 18.29383333, 19.00283333, 10.92063225],\n",
       "       [24.60767713, 24.85633333, 25.19566667, 25.22637616],\n",
       "       [31.42004163, 28.02816667, 28.20516667, 31.55975437],\n",
       "       [20.46214326, 14.796     , 18.60766667, 21.45631294],\n",
       "       [25.24927516, 24.20583333, 24.21666667, 25.51406957],\n",
       "       [27.12422317, 24.677     , 24.50216667, 27.35231137],\n",
       "       [36.33734178, 35.80566667, 37.56716667, 36.81604902],\n",
       "       [28.90179886, 23.76783333, 24.18533333, 28.26466327],\n",
       "       [28.95689167, 23.63566667, 24.5205    , 28.6958171 ],\n",
       "       [23.13128165, 20.92966667, 25.90133333, 24.35920037],\n",
       "       [20.38895091, 20.58016667, 20.5295    , 20.51699996],\n",
       "       [26.82229271, 23.149     , 23.29183333, 27.03249348],\n",
       "       [16.81524472, 14.9875    , 16.16283333, 15.98263223],\n",
       "       [15.07343322, 15.84366667, 16.32816667, 15.11003021],\n",
       "       [34.25030382, 30.16466667, 34.18866667, 34.79165014],\n",
       "       [34.81377041, 44.0375    , 42.31833333, 35.06580931],\n",
       "       [24.23595014, 21.14116667, 21.67283333, 24.09530992],\n",
       "       [30.60839562, 31.4375    , 30.81733333, 30.38889137],\n",
       "       [27.65706697, 24.8415    , 24.88483333, 27.78059674],\n",
       "       [18.55610173, 19.5965    , 19.64683333, 18.69710332],\n",
       "       [15.71725052, 17.67183333, 17.63633333, 15.8587156 ],\n",
       "       [25.55380822, 23.47666667, 23.94683333, 25.89145609],\n",
       "       [31.89285672, 33.48883333, 33.647     , 31.53211391],\n",
       "       [36.95702572, 44.53366667, 43.98816667, 36.9394308 ],\n",
       "       [27.90406825, 25.21883333, 26.33733333, 28.04918834],\n",
       "       [22.61636793, 21.78716667, 21.99      , 22.72329522],\n",
       "       [27.16957293, 21.48683333, 22.24833333, 26.28401286],\n",
       "       [24.43409833, 24.1445    , 24.743     , 24.69597841],\n",
       "       [27.78629733, 26.435     , 26.211     , 27.5756191 ],\n",
       "       [27.35729994, 21.5195    , 22.01716667, 27.35874372],\n",
       "       [17.76422132, 19.50933333, 19.941     , 17.777027  ],\n",
       "       [14.78548741, 13.51016667, 15.01933333, 16.68778358],\n",
       "       [20.57238842, 20.02066667, 20.13133333, 21.06153631],\n",
       "       [28.40241748, 27.34383333, 27.6255    , 28.31722966],\n",
       "       [25.04762088, 23.74516667, 24.2675    , 24.80811623],\n",
       "       [29.30037632, 23.663     , 24.1055    , 29.1580965 ],\n",
       "       [28.51285193, 22.30683333, 23.62666667, 29.3172388 ],\n",
       "       [32.77634074, 26.38916667, 26.32933333, 32.51918259],\n",
       "       [30.30549248, 24.249     , 24.67683333, 30.10542851],\n",
       "       [19.45943254, 20.91333333, 20.90916667, 19.75400741],\n",
       "       [20.38655237, 19.59866667, 19.52866667, 21.00873594],\n",
       "       [ 9.58676502,  9.42566667,  9.32583333,  9.39989953],\n",
       "       [19.81645206, 19.21533333, 19.30633333, 19.72768699],\n",
       "       [19.78685274, 19.57816667, 19.5825    , 19.87911355],\n",
       "       [24.43599706, 20.81083333, 21.01916667, 24.55138   ],\n",
       "       [30.13837032, 28.1135    , 28.24816667, 30.55231799],\n",
       "       [17.837327  , 18.65666667, 17.5115    , 18.03372066],\n",
       "       [19.95107346, 19.5085    , 20.2025    , 19.43999082],\n",
       "       [21.12236224, 21.34216667, 22.85816667, 23.22406667],\n",
       "       [20.04976125, 13.05133333, 11.9045    , 19.91092409],\n",
       "       [18.65090363, 20.83033333, 20.36016667, 18.91358285],\n",
       "       [32.26037222, 32.21883333, 31.9265    , 31.86711673],\n",
       "       [40.48144484, 42.89466667, 45.32866667, 41.12171841],\n",
       "       [24.55447235, 21.81766667, 22.25383333, 24.21209614],\n",
       "       [27.7801678 , 23.12666667, 23.23783333, 27.35685862],\n",
       "       [20.95862395, 23.17333333, 23.9935    , 21.50030976],\n",
       "       [23.51528508, 20.26333333, 22.20183333, 24.6286991 ],\n",
       "       [19.44651556, 20.77366667, 22.664     , 19.27925095],\n",
       "       [19.25799143, 14.38483333, 12.27466667, 19.37776125],\n",
       "       [41.98853334, 46.72966667, 47.934     , 41.72998764],\n",
       "       [40.22835473, 41.923     , 44.15833333, 40.42798057],\n",
       "       [26.63106374, 22.654     , 23.56      , 26.17077405],\n",
       "       [20.59293732, 19.48316667, 19.192     , 20.33389336],\n",
       "       [37.82930625, 44.0865    , 44.62133333, 37.44953954],\n",
       "       [28.68397357, 26.612     , 25.43016667, 28.36900111]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(oof_tests, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized weights:\n",
      "w 0: 0.0000\n",
      "w 1: 0.3485\n",
      "w 2: 0.6515\n",
      "w 3: 0.0000\n",
      "Best score: 10.7048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_predictions = np.concatenate(oof_trains, axis=1)\n",
    "\n",
    "\n",
    "def objective(weights):\n",
    "    y_ens = np.average(train_predictions, axis=1, weights=weights)\n",
    "    return mean_squared_error(y_train, y_ens)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "results_list = []    # a list to store the best score of each round\n",
    "weights_list = []    # a list to store the best weights of each round\n",
    "\n",
    "for k in range(1000):\n",
    "    # I randomly set the initial weights from which the algorithm will try searching a minima    \n",
    "    w0 = np.random.uniform(size=train_predictions.shape[1])\n",
    "\n",
    "    # I define bounds, i.e. lower and upper values of weights.\n",
    "    # I want the weights to be between 0 and 1.\n",
    "    bounds = [(0,1)] * train_predictions.shape[1]\n",
    "\n",
    "    # I set some constraints. Here, I want the sum of the weights to be equal to 1\n",
    "    cons = [{'type': 'eq',\n",
    "             'fun': lambda w: w.sum() - 1}]\n",
    "\n",
    "    # I can now search for the best weights\n",
    "    res = minimize(objective,\n",
    "                   w0,\n",
    "                   method='SLSQP',\n",
    "                   bounds=bounds,\n",
    "                   options={'disp':False, 'maxiter':1000},\n",
    "                   constraints=cons)\n",
    "\n",
    "    # I save the best score and the best weights of\n",
    "    # this round in their respective lists\n",
    "    results_list.append(res.fun)\n",
    "    weights_list.append(res.x)\n",
    "\n",
    "# After running all the rounds, I extract the best score\n",
    "# and the corresponding weights\n",
    "best_score = np.min(results_list)    \n",
    "best_weights = weights_list[results_list.index(best_score)]\n",
    "\n",
    "\n",
    "print('\\nOptimized weights:')\n",
    "for i,w in enumerate(best_weights):\n",
    "    print(f'w {i}: {w:.4f}')\n",
    "print('Best score: {:.4f}'.format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c486376ded516fafe091783a6c70b600e9bfb5824ad41de96f5bf0836d62937"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
